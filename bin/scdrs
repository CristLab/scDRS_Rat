#!/usr/bin/env python

import fire
import pandas as pd
import numpy as np
from statsmodels.stats.multitest import multipletests
import scdrs
from typing import Dict, List
from anndata import read_h5ad
import scanpy as sc
import time
import os
import fnmatch


def compute_score():
    """
    CLI for scoring cell, e.g.,
    TODO: decide whether to move compute_score.py here
    scdrs score --h5ad-file <h5ad_file> ...
    """
    pass


def munge_gs(
    out: str,
    pval_file: str = None,
    zscore_file: str = None,
    weight: str = "zscore",
    fdr: float = None,
    fwer: float = None,
    n_min: int = 100,
    n_max: int = 1000,
):
    """
    CLI for making gene set, convert a MAGMA result-like file to a gene set.
    
    <src_file> is a space-delimited file with the following formats:
    - The first column should corresponds to gene names
    - For the one or more columns to follow, the header should be the disease name,
        and the values should be the gene-level p-values.

    For example, <src_file> looks like

        GENE    BMI    HEIGHT
        OR4F5   0.001  0.01
        DAZ3    0.01   0.001
        ...
    
    This function make the gene weights with the following steps.
    1. Read result, which is assumed to  e.g., MAGMA result file
    2. Thresholding the number of genes using FDR or FWER
    3. Then cap them between `n_min` and `n_max`
    4. Write gene set to `out`

    Examples
    --------
    scdrs make-gs \
        --pval-file <pval_file> \
        --out <out> \
        --weight <weight> \
        --fdr <fdr> \
        --fwer <fwer> \
        --n-min <n_min> \
        --n-max <n_max>
    """
    # either pval_file or zscore_file should be provided
    assert (pval_file is None) != (
        zscore_file is None
    ), "Either `pval_file` or `zscore_file` should be provided"
    if zscore_file is not None:
        # convert z-score to p-values
        df_zscore = pd.read_csv(zscore_file, delim_whitespace=True)
        df_pval = df_zscore.copy()
        for col in df_pval.columns[1:]:
            df_pval[col] = scdrs.util.zsc2pval(df_zscore[col])
    else:
        df_pval = pd.read_csv(pval_file, delim_whitespace=True)

    gene_col = df_pval.columns[0]
    trait_list = df_pval.columns[1:].values

    dict_gene_weights: Dict[str, List] = {
        "TRAIT": [],
        "GENESET": [],
    }
    for trait in trait_list:
        # some p-value can be NaN
        df_trait_pval = df_pval[[gene_col, trait]].copy().dropna(axis=0)

        assert np.all(
            (0 <= df_trait_pval[trait].values) & (df_trait_pval[trait].values <= 1)
        ), f"{trait}'s p-value are not between 0 and 1"

        # Thresholding the number of genes using FDR or FWER (if specified)
        #   and cap them between `n_min` and `n_max`
        assert (fdr is None) or (
            fwer is None
        ), f"`fdr` and `fwer` can not be both specified"
        if fwer is not None:
            n_gene = (
                multipletests(df_trait_pval[trait].values, method="bonferroni")[1]
                < fwer
            )
        elif fdr is not None:
            n_gene = (
                multipletests(df_trait_pval[trait].values, method="fdr_bh")[1] < fdr
            )
        else:
            # if none of them is specified, just use the n_max
            n_gene = n_max

        # 4. cap them between `n_min` and `n_max`
        n_gene = np.minimum(n_gene, n_max)
        n_gene = np.maximum(n_gene, n_min)

        # use the `n_gene` with smallest p-value
        df_trait_pval = (
            df_trait_pval.sort_values(trait).iloc[:n_gene].reset_index(drop=True)
        )
        gene_list = df_trait_pval[gene_col].values
        gene_pvals = df_trait_pval[trait].values
        gene_pvals += 1e-16  # to avoid zero p-value
        if weight == "zscore":
            gene_weights = scdrs.util.pval2zsc(gene_pvals)
        elif weight == "uniform":
            gene_weights = np.ones(len(gene_list))
        else:
            raise ValueError(f"Unknown gene weight option {weight}")

        dict_gene_weights["TRAIT"].append(trait)
        dict_gene_weights["GENESET"].append(
            ",".join([f"{g}:{w:.5g}" for g, w in zip(gene_list, gene_weights)])
        )
    df_gs = pd.DataFrame(dict_gene_weights)
    df_gs.to_csv(out, sep="\t", index=False)


def perform_downstream(
    h5ad_file: str,
    score_file: str,
    out_folder: str,
    group_analysis: str = None,
    corr_analysis: str = None,
    gene_analysis: str = None,
    filter_data: bool = False,
    raw_count: bool = True,
):
    """
    CLI for group-level analysis, e.g.,

    scdrs group-analysis --h5ad-file <h5ad_file> ...

    Parameters
    ----------
    h5ad_file: str
        Path to the h5ad file
    score_file: str
        Path to the score file
    out_folder: str
        Path to the output folder
    group_list: str
        Comma-seperated column names for variables representing groups
        (e.g., cell types or tissues)
    """
    sys_start_time = time.time()

    # check arguments
    assert (
        (group_analysis is not None)
        + (corr_analysis is not None)
        + (gene_analysis is not None)
    ) == 1, (
        "only one of `group_analysis`, `corr_analysis`, `gene_analyis` can be specified"
    )

    # Load .h5ad file
    adata = read_h5ad(h5ad_file)
    if filter_data:
        sc.pp.filter_cells(adata, min_genes=250)
        sc.pp.filter_genes(adata, min_cells=50)
    if raw_count:
        sc.pp.normalize_per_cell(adata, counts_per_cell_after=1e4)
        sc.pp.log1p(adata)
    print(
        "--h5ad_file loaded: n_cell=%d, n_gene=%d (sys_time=%0.1fs)"
        % (adata.shape[0], adata.shape[1], time.time() - sys_start_time)
    )

    # Load score file
    score_file_pattern = score_file.split(os.path.sep)[-1]
    score_dir = score_file.replace(os.path.sep + score_file_pattern, "")
    score_file_list = [
        x
        for x in os.listdir(score_dir)
        if fnmatch.fnmatch(x, score_file_pattern.replace("@", "*"))
    ]
    print("Infer score_dir=%s" % score_dir)
    print("Find %s score_files: %s" % (len(score_file_list), ",".join(score_file_list)))
    dic_score = {}
    for score_file in score_file_list:
        temp_df = pd.read_csv(
            score_dir + os.path.sep + score_file, sep="\t", index_col=0
        )
        n_cell_overlap = len(set(adata.obs_names) & set(temp_df.index))
        if n_cell_overlap < 0.1 * adata.shape[0]:
            print(
                "WARNING: %s skipped, %d/%d cells in adata"
                % (score_file, n_cell_overlap, adata.shape[0])
            )
        else:
            dic_score[score_file.replace(".full_score.gz", "")] = temp_df.copy()

    print(
        "--score_file loaded: n_trait=%d, (sys_time=%0.1fs)"
        % (len(dic_score), time.time() - sys_start_time)
    )
    print("")

    ###########################################################################################
    ######                                  Computation                                  ######
    ###########################################################################################

    # preprocess arguments
    group_list = []
    var_list = []
    if group_analysis is not None:
        if isinstance(group_analysis, str):
            group_list.extend(group_analysis.split(","))
        elif isinstance(group_analysis, tuple):
            group_list.extend([g for g in group_analysis])
        else:
            raise ValueError("group_analysis should be a string or a tuple of strings")
        if "connectivities" not in adata.obsp:
            sc.pp.neighbors(adata, n_neighbors=10, n_pcs=40)
            print(
                "Compute connectivities with `sc.pp.neighbors`"
                "because `connectivities` is not found in adata.obsp"
            )
    elif corr_analysis is not None:
        if isinstance(corr_analysis, str):
            var_list.extend(corr_analysis.split(","))
        elif isinstance(corr_analysis, tuple):
            var_list.extend([v for v in corr_analysis])
        else:
            raise ValueError("corr_analysis should be a string or a tuple of strings")
    elif gene_analysis is not None:
        pass
    else:
        raise ValueError("No analysis specified")

    # A separate file for each trait
    for trait in dic_score.keys():
        cell_list = sorted(set(adata.obs_names) & set(dic_score[trait].index))
        control_list = [
            x for x in dic_score[trait].columns if x.startswith("ctrl_norm_score")
        ]
        n_ctrl = len(control_list)
        df_reg = adata.obs.loc[cell_list, group_list + var_list].copy()
        df_reg = df_reg.join(
            dic_score[trait].loc[cell_list, ["norm_score"] + control_list]
        )
        if group_analysis is not None:
            # Cell type-disease analysis: association + heterogeneity
            for ct_col in group_list:
                ct_list = sorted(set(adata.obs[ct_col]))
                col_list = [
                    "n_cell",
                    "n_ctrl",
                    "assoc_mcp",
                    "assoc_mcz",
                    "hetero_mcp",
                    "hetero_mcz",
                ]
                df_res = pd.DataFrame(index=ct_list, columns=col_list, dtype=np.float32)
                # Basic info
                for ct in ct_list:
                    ct_cell_list = list(df_reg.index[df_reg[ct_col] == ct])
                    df_res.loc[ct, ["n_cell", "n_ctrl"]] = [len(ct_cell_list), n_ctrl]
                # Association
                for ct in ct_list:
                    ct_cell_list = list(df_reg.index[df_reg[ct_col] == ct])
                    score_q95 = np.quantile(
                        df_reg.loc[ct_cell_list, "norm_score"], 0.95
                    )
                    v_ctrl_score_q95 = np.quantile(
                        df_reg.loc[ct_cell_list, control_list], 0.95, axis=0
                    )
                    mc_p = ((v_ctrl_score_q95 >= score_q95).sum() + 1) / (
                        v_ctrl_score_q95.shape[0] + 1
                    )
                    mc_z = (
                        score_q95 - v_ctrl_score_q95.mean()
                    ) / v_ctrl_score_q95.std()
                    df_res.loc[ct, ["assoc_mcp", "assoc_mcz"]] = [mc_p, mc_z]
                # Heterogeneity
                df_rls = scdrs.util.test_gearysc(adata, df_reg, groupby=ct_col)
                for ct in ct_list:
                    mc_p, mc_z = df_rls.loc[ct, ["pval", "zsc"]]
                    df_res.loc[ct, ["hetero_mcp", "hetero_mcz"]] = [mc_p, mc_z]

                df_res.to_csv(
                    os.path.join(
                        out_folder, "%s.scdrs_ct.%s" % (trait, ct_col.replace(" ", "_"))
                    ),
                    sep="\t",
                    index=True,
                )
                print(
                    "%s: cell type-level analysis with label=%s (sys_time=%0.1fs)"
                    % (trait, ct_col, time.time() - sys_start_time)
                )
        elif corr_analysis is not None:
            # Variable-disease correlation
            if len(var_list) > 0:
                col_list = ["n_ctrl", "corr_mcp", "corr_mcz"]
                df_res = pd.DataFrame(
                    index=var_list, columns=col_list, dtype=np.float32
                )
                for var_col in var_list:
                    corr_ = np.corrcoef(df_reg[var_col], df_reg["norm_score"])[0, 1]
                    v_corr_ = np.array(
                        [
                            np.corrcoef(
                                df_reg[var_col], df_reg["ctrl_norm_score_%d" % x]
                            )[0, 1]
                            for x in np.arange(n_ctrl)
                        ]
                    )
                    mc_p = ((v_corr_ >= corr_).sum() + 1) / (v_corr_.shape[0] + 1)
                    mc_z = (corr_ - v_corr_.mean()) / v_corr_.std()
                    df_res.loc[var_col] = [n_ctrl, mc_p, mc_z]
                df_res.to_csv(
                    os.path.join(out_folder, "%s.scdrs_var" % trait),
                    sep="\t",
                    index=True,
                )
                print(
                    "%s: cell-level variable-disease correlation analysis (sys_time=%0.1fs)"
                    % (trait, time.time() - sys_start_time)
                )
        elif gene_analysis is not None:
            # Gene prioritization
            mat_expr = adata[df_reg.index].X.copy()
            v_corr = scdrs.method._pearson_corr(mat_expr, df_reg["norm_score"].values)
            df_res = pd.DataFrame(
                index=adata.var_names, columns=["CORR", "RANK"], dtype=np.float32
            )
            df_res["CORR"] = v_corr
            df_res.sort_values("CORR", ascending=False, inplace=True)
            df_res["RANK"] = np.arange(df_res.shape[0])
            df_res.to_csv(
                os.path.join(out_folder, "%s.scdrs_gene" % trait), sep="\t", index=True
            )
            print(
                "%s: disease gene prioritization (sys_time=%0.1fs)"
                % (trait, time.time() - sys_start_time)
            )
        else:
            print("%s: no analysis" % trait)


if __name__ == "__main__":
    fire.Fire()